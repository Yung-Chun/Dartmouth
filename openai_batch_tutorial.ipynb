{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a skeleton code of OpenAI batch processing. For more technical details, see the [official document](https://platform.openai.com/docs/guides/batch).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tiktoken\n",
    "import requests\n",
    "import ast\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai import RateLimitError, APIError, APIConnectionError, APITimeoutError, InternalServerError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API keys\n",
    "- Create an .env file and store the keys for security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or_update_token(env_file, token_name, token_value):\n",
    "    # Read the existing .env file\n",
    "    env_file_path = Path(env_file)\n",
    "    if not env_file_path.exists():\n",
    "        print(f\"{env_file} does not exist.\")\n",
    "        # create an .env file\n",
    "        env_file_path.touch()\n",
    "        print(f\".env file created at {env_file_path}\")\n",
    "    \n",
    "    # Read lines from the .env file\n",
    "    with open(env_file, 'r') as file:\n",
    "        print(f\"{env_file} exists.\")\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Track if the token was updated\n",
    "    token_exists = False\n",
    "    \n",
    "    # Modify the existing token if it exists\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(f\"{token_name}=\"):\n",
    "            print(f\"{token_name} already exists.\")\n",
    "            lines[i] = f\"{token_name}={token_value}\\n\"\n",
    "            token_exists = True\n",
    "            break\n",
    "    \n",
    "    # If the token does not exist, append it\n",
    "    if not token_exists:\n",
    "        print(f\"Add {token_name}.\")\n",
    "        lines.append(f\"{token_name}={token_value}\\n\")\n",
    "    \n",
    "    # Write the lines back to the .env file\n",
    "    with open(env_file, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "    \n",
    "    print(f\"Token {token_name} has been {'updated' if token_exists else 'added'} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_or_update_token('your .env path', 'OPENAI_API_KEY', 'your opanai api key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env file exists\n"
     ]
    }
   ],
   "source": [
    "# # Reading from the .env file to verify contents\n",
    "folder_path = 'your_folder_path'\n",
    "env_file_path = os.path.join(folder_path, '.env')\n",
    "\n",
    "with open(env_file_path, 'r') as file:\n",
    "    # print(file.read())\n",
    "    print('.env file exists')\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path = env_file_path)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai_org_id = os.getenv('OPENAI_ORG_ID')\n",
    "\n",
    "# Set the environment variables\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ['OPENAI_ORG_ID'] = openai_org_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dataset\n",
    "-  Make sure the type of **id** is *string*\n",
    "-  If it is image, convert to *base64*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('your_csv_path')\n",
    "\n",
    "# preprocess the data\n",
    "data = raw_data[['id', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model\n",
    "- For available models, see [Model Availability](https://platform.openai.com/docs/guides/batch/model-availability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "\n",
    "# For example, the prompt can be:\n",
    "label_system_prompt = '''\n",
    "As a political researcher analyzing U.S. elections, your goal is to evaluate the political standpoint expressed in a provided post. \n",
    "Each indicator should represent whether the post supports or opposes various political figures or parties.\n",
    "Based on the post's content, you will need to output a JSON object containing various binary indicators (0 or 1) reflecting specific conditions:\n",
    "\n",
    "{\n",
    "    pro_democrat: int, // Set to 1 if the post supports the Democratic party, otherwise 0,\n",
    "    against_democrat: int, // Set to 1 if the post opposes the Democratic party, otherwise 0,\n",
    "    pro_republican: int, // Set to 1 if the post supports the Republican party, otherwise 0,\n",
    "    against_republican: int, // Set to 1 if the post opposes the Republican party, otherwise 0,\n",
    "    pro_biden: int, // Set to 1 if the post supports Joe Biden, otherwise 0,\n",
    "    against_biden: int, // Set to 1 if the post opposes Joe Biden, otherwise 0,\n",
    "    pro_trump: int, // Set to 1 if the post supports Donald Trump, otherwise 0,\n",
    "    against_trump: int, // Set to 1 if the post opposes Donald Trump, otherwise 0,\n",
    "    pro_kamala: int, // Set to 1 if the post supports Kamala Harris, otherwise 0,\n",
    "    against_kamala: int // Set to 1 if the post opposes Kamala Harris, otherwise 0\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create batch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model name\n",
    "# model_name = \"gpt-4o\"\n",
    "model_name = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task(row):\n",
    "    return {\n",
    "        \"custom_id\": str(row.id), #must ensure the id is string and unique\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model_name,\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 120,\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": label_system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": row.text\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of tasks: 199316\n"
     ]
    }
   ],
   "source": [
    "tasks = []\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    task = create_task(row)\n",
    "    tasks.append(task)\n",
    "\n",
    "print(f'num of tasks: {len(tasks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tasks), type(tasks[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': '7325221162672508206',\n",
       " 'method': 'POST',\n",
       " 'url': '/v1/chat/completions',\n",
       " 'body': {'model': 'gpt-4o-mini',\n",
       "  'temperature': 0.1,\n",
       "  'max_tokens': 120,\n",
       "  'response_format': {'type': 'json_object'},\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': \"\\nAs a political researcher analyzing U.S. elections, your goal is to evaluate the political standpoint expressed in a provided post. \\nEach indicator should represent whether the post supports or opposes various political figures or parties.\\nBased on the post's content, you will need to output a JSON object containing various binary indicators (0 or 1) reflecting specific conditions:\\n\\n{\\n    pro_democrat: int, // Set to 1 if the post supports the Democratic party, otherwise 0,\\n    against_democrat: int, // Set to 1 if the post opposes the Democratic party, otherwise 0,\\n    pro_republican: int, // Set to 1 if the post supports the Republican party, otherwise 0,\\n    against_republican: int, // Set to 1 if the post opposes the Republican party, otherwise 0,\\n    pro_biden: int, // Set to 1 if the post supports Joe Biden, otherwise 0,\\n    against_biden: int, // Set to 1 if the post opposes Joe Biden, otherwise 0,\\n    pro_trump: int, // Set to 1 if the post supports Donald Trump, otherwise 0,\\n    against_trump: int, // Set to 1 if the post opposes Donald Trump, otherwise 0,\\n    pro_kamala: int, // Set to 1 if the post supports Kamala Harris, otherwise 0,\\n    against_kamala: int // Set to 1 if the post opposes Kamala Harris, otherwise 0\\n}\\n\"},\n",
       "   {'role': 'user',\n",
       "    'content': '#duet with @ChiodoSupply #democrat #Fuc#Trump #replubacation #lier #trader #richbrats #pos '}]}}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch functions\n",
    "- Must make sure the batch file is an *object*, not a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tasks\n",
    "file_name = 'batch_task_file.jsonl'\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "    for obj in tasks:\n",
    "        f.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeBatchTasks(batch_data, file_name, directory='batch_tasks'):\n",
    "    # Create the directory if it doesn't exist\n",
    "    path = Path(directory)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = path / file_name\n",
    "\n",
    "    try:\n",
    "        with file_path.open('w') as f:\n",
    "            for obj in batch_data:\n",
    "                f.write(json.dumps(obj) + '\\n')\n",
    "        print(f'File {file_path} created with {len(batch_data)} requests.', end='\\n\\n')\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload batch file\n",
    "def uploadBatchFile(file_name, directory='batch_tasks'):\n",
    "    file_path = Path(directory) / file_name\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"Error: File {file_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    print('Uploading batch file...')\n",
    "\n",
    "    try:\n",
    "        with file_path.open('rb') as file:\n",
    "            batch_file = client.files.create(\n",
    "                file=file,\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "        print('Batch file name:', batch_file.filename)\n",
    "        print('Batch file ID:', batch_file.id)\n",
    "        print('Batch file status:', batch_file.status, end='\\n\\n')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file: {e}\")\n",
    "        return None\n",
    "\n",
    "    return batch_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch job\n",
    "def createBatchJob(batch_file, endpoint=\"/v1/chat/completions\", completion_window=\"24h\"):\n",
    "    print('Creating batch job...')\n",
    "    try:\n",
    "        batch_job = client.batches.create(\n",
    "            input_file_id=batch_file.id,\n",
    "            endpoint=endpoint,\n",
    "            completion_window=completion_window\n",
    "        )\n",
    "        print('Batch job ID:', batch_job.id)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating batch job: {e}\")\n",
    "        return None\n",
    "\n",
    "    return batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBatchJobStatus(batch_job_id, check_interval=3):\n",
    "    batch_job = client.batches.retrieve(batch_job_id)\n",
    "    final_statuses = {'completed', 'failed', 'expired', 'cancelled'}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            batch_job = client.batches.retrieve(batch_job_id)\n",
    "            current_status = batch_job.status.lower()\n",
    "            \n",
    "            print(f\"Current status of job {batch_job_id}: {current_status}\")\n",
    "            \n",
    "            if current_status in final_statuses:\n",
    "                print(f\"Job {batch_job_id} has reached a final status: {current_status}\")\n",
    "                return current_status\n",
    "            \n",
    "            if current_status == 'finalizing':\n",
    "                print(f\"Job {batch_job_id} is finalizing. Checking again in 2 minutes...\")\n",
    "                time.sleep(2 * 60)\n",
    "\n",
    "            else:\n",
    "                print(f\"Job {batch_job_id} is still {current_status}. Checking again in {check_interval} minutes...\")\n",
    "                time.sleep(check_interval * 60)  # Convert minutes to seconds\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while checking job {batch_job_id}: {str(e)}\")\n",
    "            print(f\"Retrying in {check_interval} minutes...\")\n",
    "            time.sleep(check_interval * 60)\n",
    "\n",
    "        print('===========================', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjust the batch_size based on the API rate limits and your data\n",
    "- Try and check before loop all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of requests\n",
    "batch_size = 2500 \n",
    "num_files = (len(tasks) + batch_size - 1) // batch_size\n",
    "print(f'Total requests: {len(tasks)}. Batch size: {batch_size}. Separated in {num_files} files.', end='\\n\\n')\n",
    "\n",
    "batch_job_records = []\n",
    "\n",
    "# Save data in chunks\n",
    "for i in range(num_files):\n",
    "    start_index = i * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    \n",
    "    # Slice the list to get the current batch\n",
    "    batch_data = tasks[start_index:end_index]\n",
    "    \n",
    "    # Create a filename\n",
    "    file_name = f'batch_task_file{i+1}.jsonl'\n",
    "\n",
    "    # record the batch job\n",
    "    batch_job_records.append({\n",
    "        'file_name': file_name,\n",
    "        'start_index': start_index,\n",
    "        'end_index': end_index\n",
    "    })\n",
    "    \n",
    "    # Write batch tasks\n",
    "    writeBatchTasks(batch_data, file_name)\n",
    "\n",
    "    # Upload batch file\n",
    "    batch_file = uploadBatchFile(file_name)\n",
    "    if not batch_file:\n",
    "        print(f\"Failed to upload file {file_name}. Skipping this batch.\")\n",
    "        continue\n",
    "    \n",
    "    # Create batch job\n",
    "    batch_job = createBatchJob(batch_file)\n",
    "    if not batch_job:\n",
    "        print(f\"Failed to create batch job for file {file_name}.\")\n",
    "        print(batch_job.errors.data)\n",
    "        continue\n",
    "    \n",
    "    # Check batch job status, until it reaches a final status\n",
    "    final_statuses = {'completed', 'failed', 'expired', 'cancelled'}\n",
    "    final_status = checkBatchJobStatus(batch_job.id)\n",
    "    if final_status in final_statuses:\n",
    "        print(f\"Batch job {batch_job.id} is {final_status}.\")\n",
    "        continue\n",
    "\n",
    "print(\"Batch processing completed.\")\n",
    "\n",
    "# save batch job records as a jsonl file\n",
    "with open('batch_job_records.jsonl', 'w') as f:\n",
    "    for obj in batch_job_records:\n",
    "        f.write(json.dumps(obj) + '\\n')\n",
    "print('Batch job records saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = []\n",
    "\n",
    "for batch in client.batches.list(after='the head batch id'):\n",
    "    if batch.id == 'the tail batch id':\n",
    "        break\n",
    "    print(batch.id, batch.status)\n",
    "    output_files.append([batch.id, batch.created_at, batch.output_file_id])\n",
    "\n",
    "print(len(output_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = sorted(output_files, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'batch_output'\n",
    "for idx, output_file in enumerate(output_files):\n",
    "    path = Path(directory)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    output_file_name = 'batch_task_file{}.json'.format(idx+1)\n",
    "    file_path = path / output_file_name\n",
    "\n",
    "    result = client.files.content(output_files[idx][2]).content\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "directory = 'batch_output'\n",
    "output_files = glob(f'{directory}/*.json')\n",
    "\n",
    "for file_path in output_files:\n",
    "    print(file_path)\n",
    "    #Â Loading data from saved file\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parsing the JSON string into a dict and appending to the list of results\n",
    "            json_object = json.loads(line.strip())\n",
    "            custom_id = json_object['custom_id']\n",
    "            res = json.loads(json_object['response']['body']['choices'][0]['message']['content']).values()\n",
    "        \n",
    "            results.append([custom_id] + list(res))\n",
    "            # print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the results to the original data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
